{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This is just a rough skeleton to assist you in understanding the process flow. \n",
    "Modify it to meet the requirements of the questions. \n",
    "\n",
    "Put the description paragraph here\n",
    "DESCRIPTION OF IMPLEMENTATION:\n",
    "\n",
    "Firstly, to prepare the data, I shuffled the index of the data, then used this index to shuffle the data. \n",
    "Then partition them into equal k=5 folds.\n",
    "And, save them into the dictionary X_shuffled and y_shuffled respectively.\n",
    "\n",
    "Then set itr as the parameter that the key whose value will be chosed for the valid data, and the leftover will be the train data.\n",
    "Where I used the \"pop\" function to seperate the valid data and the train data and use \"np.concatenate\" to connection the separated \n",
    "train data.\n",
    "\n",
    "Secondly, in order to train the data, I used the formula derived in the Problem 2 which is the loglikelihood of logistic function,\n",
    "besides, I also use the cost function to get the gradient which will be used in the gradient descent.\n",
    "\n",
    "In the gradient descent process, alpha is the learning rate hyperparameter. And I set the convergence desicion boundary is the norm of w(t+1)-w(t) is less than 0.0001, and the iteration time is less than 2000.\n",
    "\n",
    "To valid this method, I uses the X_valid times coefficient matrix to get the y_predict.\n",
    "\n",
    "Finally, for every alpha, we train the dataset and valid the methon 5 times, and get 5 error rate, I use their mean value \n",
    "as the final errorate for this alpha method.\n",
    "\n",
    "Choose different lambda and get different error rate. Plot error rate vs alpha.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading the data you can use either numpy or pandas and accordingly handle your processing. An example could be\n",
    "# my_data = np.genfromtxt('SPAM-HW1.csv', delimiter=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "features=pd.read_csv(\"IRISFeat.csv\")# in this way the data will be dataframe\n",
    "labels=pd.read_csv(\"IRISlabel.csv\")\n",
    "n=len(features)\n",
    "k=features.shape[1]\n",
    "f=5\n",
    "\n",
    "#shuffle the data\n",
    "shuffled_index=np.random.permutation(n)\n",
    "features_shuffled=features.iloc[shuffled_index]\n",
    "labels_shuffled=labels.iloc[shuffled_index]\n",
    "\n",
    "#partition them into equal 5 folds\n",
    "fea=[]\n",
    "for i in range(1,f+1):\n",
    "    fold=features_shuffled.iloc[(i-1)*(int(n/f)):i*(int(n/f)),:]\n",
    "    fea.append(fold)\n",
    "\n",
    "lab=[]\n",
    "for j in range(1,f+1):\n",
    "    fold=labels_shuffled.iloc[(j-1)*(int(n/f)):j*(int(n/f)),:]\n",
    "    lab.append(fold)\n",
    "\n",
    "#Save each of the 5 folds into dictionary X_shuffled and y_shuffled\n",
    "X_shuffled={1:fea[0],2:fea[1],3:fea[2],4:fea[3],5:fea[4]}\n",
    "y_shuffled={1:lab[0],2:lab[1],3:lab[2],4:lab[3],5:lab[4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_train_valid(X_shuffled, y_shuffled, itr):\n",
    "    \"\"\"\n",
    "    - itr value can tell you which fold you pick up for valid and rest go to training\n",
    "    - use 1 fold for validation and all other folds for training\n",
    "    - in next iteration, use a different fold for validation and remaining folds for training\n",
    "        \n",
    "    Basically, here you will determine which fold goes for validation and which ones for training\n",
    "    \"\"\"\n",
    "    #return training and validation data\n",
    "    \n",
    "    #get the valid data\n",
    "    X_valid=X_shuffled[itr]\n",
    "    #design the X_valid matrix: adding a row of 1 which will times the intercept\n",
    "    X_valid=np.concatenate((np.ones((int(n/f),1)),X_valid),axis = 1)\n",
    "    y_valid=y_shuffled[itr]\n",
    "    \n",
    "    #get the shuffled data\n",
    "    Xcopy=X_shuffled.copy()\n",
    "    ycopy=y_shuffled.copy()\n",
    "    Xcopy.pop(itr)\n",
    "    ycopy.pop(itr)\n",
    "    Xtrain=Xcopy\n",
    "    ytrain=ycopy\n",
    "    #get X_train\n",
    "    X_train=np.zeros((1,k))\n",
    "    for key in Xtrain:\n",
    "        X_train=np.concatenate((X_train,Xtrain[key]),axis = 0)\n",
    "    \n",
    "    X_train=np.delete(X_train,0,axis = 0)\n",
    "    X_train=np.concatenate((np.ones(((n-int(n/f)),1)),X_train),axis = 1)\n",
    "    \n",
    "    #get y_train\n",
    "    y_train=np.zeros((1,1))\n",
    "    for key in ytrain:\n",
    "        y_train=np.concatenate((y_train,ytrain[key]),axis = 0)\n",
    "    \n",
    "    y_train=np.delete(y_train,0,axis = 0)\n",
    "    \n",
    "    return(X_train,y_train,X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivitiveF(X_train, y_train, w):\n",
    "    \"\"\"\n",
    "    Define the gradient, the devitation has been derived in the Problem 2 and I also use the cost function.\n",
    "    \"\"\"\n",
    "    log=1/(1+np.exp(-np.dot(X_train,w)))\n",
    "    grad=(1/(n-(n/f)))*(np.dot(X_train.T,log-y_train))\n",
    "    \n",
    "    return(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train,alpha):\n",
    "    \"\"\"\n",
    "    This function uses gradient descent to get the coefficient matrix. \n",
    "    alpha: learning rate\n",
    "    \"\"\"\n",
    "    sita=np.random.randn(k+1,1)\n",
    "    stia=np.ones((k+1,1))\n",
    "    # return model\n",
    "    i=0\n",
    "    while (np.linalg.norm(stia-sita)>0.0001) and i<=2000:\n",
    "        stia=sita\n",
    "        deriv=derivitiveF(X_train, y_train, stia)\n",
    "        sita=stia-alpha*deriv\n",
    "        i+=1\n",
    "        \n",
    "    return(sita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_valid, sita):\n",
    "    \"\"\"\n",
    "    Here, using the trained model, implement how to predict when you just have feature vector. \n",
    "    \"\"\"\n",
    "    # return \n",
    "    #return (1*(1/(1+np.exp(-np.dot(X_valid,sita)))))\n",
    "    return 1*((1/(1+np.exp(-np.dot(X_valid,sita))))>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorate(alpha):\n",
    "    \"\"\"\n",
    "    Use all the functions above: get the train data and valid data; use gradient descent to get the coefficient matrix;\n",
    "    then let the X_valid times coefficient matrix to get y_predict. Finally, for every learning rate alpha , we have 5 \n",
    "    train datasets and 5 valid datasets, then we can get 5 error rate by counting the numbers of wrong prediction and letting \n",
    "    them divided by the whole numbers of the valid data. Take their mean value as the error rate as this learning rate method.\n",
    "    \"\"\"\n",
    "    er=np.zeros((f))\n",
    "    for i in range(1,f+1):\n",
    "        X_train,y_train,X_valid,y_valid=get_next_train_valid(X_shuffled, y_shuffled, i)\n",
    "        ww=train(X_train, y_train,alpha)\n",
    "        y_predict=predict(X_valid, ww)\n",
    "        k=np.sum(np.absolute(y_predict-y_valid))\n",
    "        er[i-1]=k/(n/f)\n",
    "        \n",
    "    errorate=np.mean(er)\n",
    "        \n",
    "    return(errorate)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08]\n",
      "[0.01333333 0.00666667 0.00666667 0.00666667 0.00666667 0.00666667\n",
      " 0.00666667 0.00666667]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r=10\n",
    "alpha=np.zeros((r))\n",
    "err=np.zeros((r))\n",
    "for j in range(0,r):\n",
    "    alpha[j]=j\n",
    "    err[j]=errorate(0.01*j)\n",
    "    \n",
    "plt.plot(0.01*alpha[1:9],err[1:9])\n",
    "print(0.01*alpha[1:9])\n",
    "print(err[1:9])\n",
    "plt.xlabel('learning rate'); \n",
    "plt.ylabel('error rate'); \n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "The reason that I chose the learning rate is that I have chose larger number like 0.5 and smaller number like 0.001, the error rates for those method are much larger than the error rate when the learning rate is 0.01. So, I try fix learning rate in the 0.01 magnitude. And find that when learning rate is 0.01 or 0.02, the error rate will change between 0.013 and 0.02. But, when learning rate is 0.02, 0.03, 0.04, ....0.09, the learning rate is fixed at 0.00666666666.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main - Here goes the overall logic.\n",
    "\"\"\"\n",
    "# cross-validation to get train and validation data\n",
    "# We will use cross validation for training and validation. In this assignment, we will not use test split separately.\n",
    "#  Let us say we want k-fold with k=5 - shuffle the data and partition into k-equal partitions\n",
    "#  Save paritions into dictionaries\n",
    "\n",
    "#Loop through 5 times, each time selecting 1 fold as validation and remaining as train data sets using function get_next_train_valid \n",
    "#   train your model\n",
    "#   predict target on validation and training\n",
    "#   compute error i.e. RMSE or classification accuracy as per assignment question\n",
    "#\n",
    "#Plot or print as per question - Mean RMSE or accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
